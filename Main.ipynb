{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "006a85a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from hls4ml.converters import convert_from_keras_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1\n",
    "from qkeras.qlayers import QDense, QActivation\n",
    "from qkeras.quantizers import quantized_bits, quantized_relu\n",
    "from callbacks import all_callbacks\n",
    "\n",
    "os.environ['PATH'] = '/home/bcilab/Xilinx/Vivado/2019.1/bin:' + os.environ['PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed95d9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'npy'\n",
    "MODEL_DIR = 'model'\n",
    "\n",
    "BOARD_NAME = 'ultra96v2'\n",
    "FPGA_PART = 'xczu3eg-sbva484-1-e'\n",
    "\n",
    "CLOCK_PERIOD = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3ebc3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load and scale dataset\n"
     ]
    }
   ],
   "source": [
    "# Load and scale dataset\n",
    "#\n",
    "print(\"Load and scale dataset\")\n",
    "data = fetch_openml('hls4ml_lhc_jets_hlf')\n",
    "X, y = data['data'], data['target']\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "y = to_categorical(y, 5)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train_val = scaler.fit_transform(X_train_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "np.save('y_test.npy', y_test)\n",
    "np.save('X_test.npy', X_test)\n",
    "np.save('classes.npy', le.classes_, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d91f633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create model\n"
     ]
    }
   ],
   "source": [
    "# Model\n",
    "print(\"Create model\")\n",
    "model = Sequential()\n",
    "model.add(QDense(64, input_shape=(16,), name='fc1',\n",
    "                 kernel_quantizer=quantized_bits(6,0,alpha=1), bias_quantizer=quantized_bits(6,0,alpha=1),\n",
    "                 kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "model.add(QActivation(activation=quantized_relu(6), name='relu1'))\n",
    "model.add(QDense(32, input_shape=(16,), name='fc2',\n",
    "                 kernel_quantizer=quantized_bits(6,0,alpha=1), bias_quantizer=quantized_bits(6,0,alpha=1),\n",
    "                 kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "model.add(QActivation(activation=quantized_relu(6), name='relu2'))\n",
    "model.add(QDense(32, input_shape=(16,), name='fc3',\n",
    "                 kernel_quantizer=quantized_bits(6,0,alpha=1), bias_quantizer=quantized_bits(6,0,alpha=1),\n",
    "                 kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "model.add(QActivation(activation=quantized_relu(6), name='relu3'))\n",
    "model.add(QDense(5, name='output',\n",
    "                 kernel_quantizer=quantized_bits(6,0,alpha=1), bias_quantizer=quantized_bits(6,0,alpha=1),\n",
    "                 kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "model.add(Activation(activation='softmax', name='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f32318bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bcilab/anaconda3/lib/python3.8/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:212: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  mask = self.add_variable(\n",
      "/home/bcilab/anaconda3/lib/python3.8/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:219: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  threshold = self.add_variable(\n",
      "/home/bcilab/anaconda3/lib/python3.8/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:233: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  self.pruning_step = self.add_variable(\n"
     ]
    }
   ],
   "source": [
    "# Training (or loading model)\n",
    "#\n",
    "from tensorflow_model_optimization.python.core.sparsity.keras import prune, pruning_callbacks, pruning_schedule\n",
    "from tensorflow_model_optimization.sparsity.keras import strip_pruning\n",
    "pruning_params = {'pruning_schedule' : pruning_schedule.ConstantSparsity(0.75, begin_step=2000, frequency=100)}\n",
    "model = prune.prune_low_magnitude(model, **pruning_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c6fd8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/30\n",
      "  1/487 [..............................] - ETA: 5:41 - loss: 0.7396 - accuracy: 0.7490WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0029s vs `on_train_batch_end` time: 0.0037s). Check your callbacks.\n",
      "481/487 [============================>.] - ETA: 0s - loss: 0.7399 - accuracy: 0.7514\n",
      "***callbacks***\n",
      "saving losses to model/losses.log\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.74305, saving model to model/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.74305, saving model to model/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00001: saving model to model/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00001: saving model to model/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "487/487 [==============================] - 3s 4ms/step - loss: 0.7397 - accuracy: 0.7514 - val_loss: 0.7430 - val_accuracy: 0.7505 - lr: 1.0000e-04\n",
      "Epoch 2/30\n",
      "470/487 [===========================>..] - ETA: 0s - loss: 0.7381 - accuracy: 0.7517\n",
      "***callbacks***\n",
      "saving losses to model/losses.log\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.74305 to 0.74053, saving model to model/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.74305 to 0.74053, saving model to model/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00002: saving model to model/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00002: saving model to model/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "487/487 [==============================] - 2s 4ms/step - loss: 0.7379 - accuracy: 0.7519 - val_loss: 0.7405 - val_accuracy: 0.7515 - lr: 1.0000e-04\n",
      "Epoch 3/30\n",
      "481/487 [============================>.] - ETA: 0s - loss: 0.7353 - accuracy: 0.7526\n",
      "***callbacks***\n",
      "saving losses to model/losses.log\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.74053 to 0.73817, saving model to model/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.74053 to 0.73817, saving model to model/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00003: saving model to model/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00003: saving model to model/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "487/487 [==============================] - 2s 3ms/step - loss: 0.7351 - accuracy: 0.7526 - val_loss: 0.7382 - val_accuracy: 0.7516 - lr: 1.0000e-04\n",
      "Epoch 4/30\n",
      "475/487 [============================>.] - ETA: 0s - loss: 0.7333 - accuracy: 0.7527\n",
      "***callbacks***\n",
      "saving losses to model/losses.log\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.73817 to 0.73661, saving model to model/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.73817 to 0.73661, saving model to model/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00004: saving model to model/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00004: saving model to model/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "487/487 [==============================] - 2s 3ms/step - loss: 0.7330 - accuracy: 0.7530 - val_loss: 0.7366 - val_accuracy: 0.7522 - lr: 1.0000e-04\n",
      "Epoch 5/30\n",
      "484/487 [============================>.] - ETA: 0s - loss: 0.7306 - accuracy: 0.7538\n",
      "***callbacks***\n",
      "saving losses to model/losses.log\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.73661 to 0.73420, saving model to model/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.73661 to 0.73420, saving model to model/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00005: saving model to model/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00005: saving model to model/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "487/487 [==============================] - 2s 4ms/step - loss: 0.7308 - accuracy: 0.7538 - val_loss: 0.7342 - val_accuracy: 0.7531 - lr: 1.0000e-04\n",
      "Epoch 6/30\n",
      "483/487 [============================>.] - ETA: 0s - loss: 0.7294 - accuracy: 0.7543\n",
      "***callbacks***\n",
      "saving losses to model/losses.log\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.73420 to 0.73400, saving model to model/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.73420 to 0.73400, saving model to model/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00006: saving model to model/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00006: saving model to model/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "487/487 [==============================] - 2s 4ms/step - loss: 0.7296 - accuracy: 0.7541 - val_loss: 0.7340 - val_accuracy: 0.7525 - lr: 1.0000e-04\n",
      "Epoch 7/30\n",
      "481/487 [============================>.] - ETA: 0s - loss: 0.7279 - accuracy: 0.7541\n",
      "***callbacks***\n",
      "saving losses to model/losses.log\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.73400 to 0.73201, saving model to model/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.73400 to 0.73201, saving model to model/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00007: saving model to model/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00007: saving model to model/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "487/487 [==============================] - 2s 3ms/step - loss: 0.7282 - accuracy: 0.7540 - val_loss: 0.7320 - val_accuracy: 0.7533 - lr: 1.0000e-04\n",
      "Epoch 8/30\n",
      "487/487 [==============================] - ETA: 0s - loss: 0.7260 - accuracy: 0.7547\n",
      "***callbacks***\n",
      "saving losses to model/losses.log\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.73201 to 0.72910, saving model to model/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.73201 to 0.72910, saving model to model/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00008: saving model to model/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00008: saving model to model/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "487/487 [==============================] - 2s 3ms/step - loss: 0.7260 - accuracy: 0.7547 - val_loss: 0.7291 - val_accuracy: 0.7541 - lr: 1.0000e-04\n",
      "Epoch 9/30\n",
      "480/487 [============================>.] - ETA: 0s - loss: 0.7251 - accuracy: 0.7549\n",
      "***callbacks***\n",
      "saving losses to model/losses.log\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.72910\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.72910\n",
      "\n",
      "Epoch 00009: saving model to model/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00009: saving model to model/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "487/487 [==============================] - 2s 3ms/step - loss: 0.7250 - accuracy: 0.7550 - val_loss: 0.7292 - val_accuracy: 0.7541 - lr: 1.0000e-04\n",
      "Epoch 10/30\n",
      "479/487 [============================>.] - ETA: 0s - loss: 0.7242 - accuracy: 0.7550\n",
      "***callbacks***\n",
      "saving losses to model/losses.log\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.72910 to 0.72705, saving model to model/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.72910 to 0.72705, saving model to model/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00010: saving model to model/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00010: saving model to model/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00010: saving model to model/KERAS_check_model_epoch10.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "487/487 [==============================] - 2s 3ms/step - loss: 0.7242 - accuracy: 0.7549 - val_loss: 0.7271 - val_accuracy: 0.7543 - lr: 1.0000e-04\n",
      "Epoch 11/30\n",
      "483/487 [============================>.] - ETA: 0s - loss: 0.7232 - accuracy: 0.7555\n",
      "***callbacks***\n",
      "saving losses to model/losses.log\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.72705\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.72705\n",
      "\n",
      "Epoch 00011: saving model to model/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00011: saving model to model/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "487/487 [==============================] - 2s 4ms/step - loss: 0.7234 - accuracy: 0.7555 - val_loss: 0.7283 - val_accuracy: 0.7546 - lr: 1.0000e-04\n",
      "Epoch 12/30\n",
      "479/487 [============================>.] - ETA: 0s - loss: 0.7221 - accuracy: 0.7556\n",
      "***callbacks***\n",
      "saving losses to model/losses.log\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.72705 to 0.72677, saving model to model/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.72705 to 0.72677, saving model to model/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00012: saving model to model/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00012: saving model to model/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "487/487 [==============================] - 2s 4ms/step - loss: 0.7221 - accuracy: 0.7557 - val_loss: 0.7268 - val_accuracy: 0.7549 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30\n",
      "484/487 [============================>.] - ETA: 0s - loss: 0.7212 - accuracy: 0.7559\n",
      "***callbacks***\n",
      "saving losses to model/losses.log\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.72677\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.72677\n",
      "\n",
      "Epoch 00013: saving model to model/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00013: saving model to model/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "487/487 [==============================] - 2s 4ms/step - loss: 0.7213 - accuracy: 0.7558 - val_loss: 0.7273 - val_accuracy: 0.7541 - lr: 1.0000e-04\n",
      "Epoch 14/30\n",
      "475/487 [============================>.] - ETA: 0s - loss: 0.7206 - accuracy: 0.7559\n",
      "***callbacks***\n",
      "saving losses to model/losses.log\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.72677 to 0.72491, saving model to model/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.72677 to 0.72491, saving model to model/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00014: saving model to model/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00014: saving model to model/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "487/487 [==============================] - 2s 4ms/step - loss: 0.7205 - accuracy: 0.7560 - val_loss: 0.7249 - val_accuracy: 0.7549 - lr: 1.0000e-04\n",
      "Epoch 15/30\n",
      "482/487 [============================>.] - ETA: 0s - loss: 0.7201 - accuracy: 0.7561\n",
      "***callbacks***\n",
      "saving losses to model/losses.log\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.72491 to 0.72459, saving model to model/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.72491 to 0.72459, saving model to model/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00015: saving model to model/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00015: saving model to model/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "487/487 [==============================] - 2s 4ms/step - loss: 0.7202 - accuracy: 0.7561 - val_loss: 0.7246 - val_accuracy: 0.7553 - lr: 1.0000e-04\n",
      "Epoch 16/30\n",
      "480/487 [============================>.] - ETA: 0s - loss: 0.7194 - accuracy: 0.7563\n",
      "***callbacks***\n",
      "saving losses to model/losses.log\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.72459 to 0.72222, saving model to model/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.72459 to 0.72222, saving model to model/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00016: saving model to model/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00016: saving model to model/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "487/487 [==============================] - 2s 4ms/step - loss: 0.7195 - accuracy: 0.7562 - val_loss: 0.7222 - val_accuracy: 0.7556 - lr: 1.0000e-04\n",
      "Epoch 17/30\n",
      "484/487 [============================>.] - ETA: 0s - loss: 0.7188 - accuracy: 0.7565\n",
      "***callbacks***\n",
      "saving losses to model/losses.log\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.72222\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.72222\n",
      "\n",
      "Epoch 00017: saving model to model/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00017: saving model to model/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "487/487 [==============================] - 2s 4ms/step - loss: 0.7187 - accuracy: 0.7566 - val_loss: 0.7235 - val_accuracy: 0.7555 - lr: 1.0000e-04\n",
      "Epoch 18/30\n",
      "486/487 [============================>.] - ETA: 0s - loss: 0.7180 - accuracy: 0.7567\n",
      "***callbacks***\n",
      "saving losses to model/losses.log\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.72222\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.72222\n",
      "\n",
      "Epoch 00018: saving model to model/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00018: saving model to model/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "487/487 [==============================] - 2s 4ms/step - loss: 0.7180 - accuracy: 0.7567 - val_loss: 0.7242 - val_accuracy: 0.7551 - lr: 1.0000e-04\n",
      "Epoch 19/30\n",
      "485/487 [============================>.] - ETA: 0s - loss: 0.7168 - accuracy: 0.7570\n",
      "***callbacks***\n",
      "saving losses to model/losses.log\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.72222\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.72222\n",
      "\n",
      "Epoch 00019: saving model to model/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00019: saving model to model/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "487/487 [==============================] - 2s 4ms/step - loss: 0.7167 - accuracy: 0.7570 - val_loss: 0.7224 - val_accuracy: 0.7556 - lr: 1.0000e-04\n",
      "Epoch 20/30\n",
      "485/487 [============================>.] - ETA: 0s - loss: 0.7162 - accuracy: 0.7573\n",
      "***callbacks***\n",
      "saving losses to model/losses.log\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.72222 to 0.72076, saving model to model/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.72222 to 0.72076, saving model to model/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00020: saving model to model/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00020: saving model to model/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00020: saving model to model/KERAS_check_model_epoch20.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "487/487 [==============================] - 2s 4ms/step - loss: 0.7162 - accuracy: 0.7573 - val_loss: 0.7208 - val_accuracy: 0.7565 - lr: 1.0000e-04\n",
      "Epoch 21/30\n",
      "484/487 [============================>.] - ETA: 0s - loss: 0.7159 - accuracy: 0.7574\n",
      "***callbacks***\n",
      "saving losses to model/losses.log\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.72076 to 0.72002, saving model to model/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.72076 to 0.72002, saving model to model/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00021: saving model to model/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00021: saving model to model/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "487/487 [==============================] - 2s 4ms/step - loss: 0.7159 - accuracy: 0.7574 - val_loss: 0.7200 - val_accuracy: 0.7566 - lr: 1.0000e-04\n",
      "Epoch 22/30\n",
      "486/487 [============================>.] - ETA: 0s - loss: 0.7149 - accuracy: 0.7577\n",
      "***callbacks***\n",
      "saving losses to model/losses.log\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.72002 to 0.71937, saving model to model/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.72002 to 0.71937, saving model to model/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00022: saving model to model/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00022: saving model to model/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "487/487 [==============================] - 2s 4ms/step - loss: 0.7148 - accuracy: 0.7577 - val_loss: 0.7194 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
      "Epoch 23/30\n",
      "481/487 [============================>.] - ETA: 0s - loss: 0.7145 - accuracy: 0.7575\n",
      "***callbacks***\n",
      "saving losses to model/losses.log\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.71937 to 0.71867, saving model to model/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.71937 to 0.71867, saving model to model/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00023: saving model to model/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00023: saving model to model/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "487/487 [==============================] - 2s 4ms/step - loss: 0.7145 - accuracy: 0.7575 - val_loss: 0.7187 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
      "Epoch 24/30\n",
      "478/487 [============================>.] - ETA: 0s - loss: 0.7145 - accuracy: 0.7577\n",
      "***callbacks***\n",
      "saving losses to model/losses.log\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.71867\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.71867\n",
      "\n",
      "Epoch 00024: saving model to model/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00024: saving model to model/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "487/487 [==============================] - 2s 4ms/step - loss: 0.7142 - accuracy: 0.7578 - val_loss: 0.7197 - val_accuracy: 0.7566 - lr: 1.0000e-04\n",
      "Epoch 25/30\n",
      "487/487 [==============================] - ETA: 0s - loss: 0.7137 - accuracy: 0.7579\n",
      "***callbacks***\n",
      "saving losses to model/losses.log\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.71867\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.71867\n",
      "\n",
      "Epoch 00025: saving model to model/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00025: saving model to model/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "487/487 [==============================] - 2s 4ms/step - loss: 0.7137 - accuracy: 0.7579 - val_loss: 0.7197 - val_accuracy: 0.7569 - lr: 1.0000e-04\n",
      "Epoch 26/30\n",
      "485/487 [============================>.] - ETA: 0s - loss: 0.7134 - accuracy: 0.7580\n",
      "***callbacks***\n",
      "saving losses to model/losses.log\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.71867\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.71867\n",
      "\n",
      "Epoch 00026: saving model to model/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00026: saving model to model/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "487/487 [==============================] - 2s 4ms/step - loss: 0.7134 - accuracy: 0.7580 - val_loss: 0.7217 - val_accuracy: 0.7574 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30\n",
      "473/487 [============================>.] - ETA: 0s - loss: 0.7129 - accuracy: 0.7580\n",
      "***callbacks***\n",
      "saving losses to model/losses.log\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.71867\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.71867\n",
      "\n",
      "Epoch 00027: saving model to model/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00027: saving model to model/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "487/487 [==============================] - 2s 4ms/step - loss: 0.7132 - accuracy: 0.7578 - val_loss: 0.7201 - val_accuracy: 0.7570 - lr: 1.0000e-04\n",
      "Epoch 28/30\n",
      "487/487 [==============================] - ETA: 0s - loss: 0.7126 - accuracy: 0.7583\n",
      "***callbacks***\n",
      "saving losses to model/losses.log\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.71867\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.71867\n",
      "\n",
      "Epoch 00028: saving model to model/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00028: saving model to model/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "487/487 [==============================] - 2s 4ms/step - loss: 0.7126 - accuracy: 0.7583 - val_loss: 0.7198 - val_accuracy: 0.7571 - lr: 1.0000e-04\n",
      "Epoch 29/30\n",
      "474/487 [============================>.] - ETA: 0s - loss: 0.7124 - accuracy: 0.7582\n",
      "***callbacks***\n",
      "saving losses to model/losses.log\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.71867 to 0.71620, saving model to model/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.71867 to 0.71620, saving model to model/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 00029: saving model to model/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00029: saving model to model/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "487/487 [==============================] - 2s 4ms/step - loss: 0.7124 - accuracy: 0.7582 - val_loss: 0.7162 - val_accuracy: 0.7577 - lr: 1.0000e-04\n",
      "Epoch 30/30\n",
      "486/487 [============================>.] - ETA: 0s - loss: 0.7119 - accuracy: 0.7584\n",
      "***callbacks***\n",
      "saving losses to model/losses.log\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.71620\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.71620\n",
      "\n",
      "Epoch 00030: saving model to model/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 00030: saving model to model/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 00030: saving model to model/KERAS_check_model_epoch30.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "487/487 [==============================] - 2s 4ms/step - loss: 0.7120 - accuracy: 0.7584 - val_loss: 0.7184 - val_accuracy: 0.7568 - lr: 1.0000e-04\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "train = True\n",
    "if train:\n",
    "    adam = Adam(lr=0.0001)\n",
    "    model.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "    callbacks = all_callbacks(stop_patience = 1000,\n",
    "                              lr_factor = 0.5,\n",
    "                              lr_patience = 10,\n",
    "                              lr_epsilon = 0.000001,\n",
    "                              lr_cooldown = 2,\n",
    "                              lr_minimum = 0.0000001,\n",
    "                              outputDir = 'model')\n",
    "    callbacks.callbacks.append(pruning_callbacks.UpdatePruningStep())\n",
    "    model.fit(X_train_val, y_train_val, batch_size=1024,\n",
    "              epochs=30, validation_split=0.25, shuffle=True,\n",
    "              callbacks = callbacks.callbacks)\n",
    "    # Save the model again but with the pruning 'stripped' to use the regular layer types\n",
    "    model = strip_pruning(model)\n",
    "    model.save('model/KERAS_check_best_model.h5')\n",
    "else:\n",
    "    from tensorflow.keras.models import load_model\n",
    "    from qkeras.utils import _add_supported_quantized_objects\n",
    "    co = {}\n",
    "    _add_supported_quantized_objects(co)\n",
    "    model = load_model('model/KERAS_check_best_model.h5', custom_objects=co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91b5a69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run prediction\n"
     ]
    }
   ],
   "source": [
    "print(\"Run prediction\")\n",
    "y_keras = model.predict(X_test)\n",
    "np.save('y_qkeras.npy', y_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99c92094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: Input\n",
      "Layer name: fc1, layer type: QDense\n",
      "Layer name: relu1, layer type: QActivation\n",
      "Layer name: fc2, layer type: QDense\n",
      "Layer name: relu2, layer type: QActivation\n",
      "Layer name: fc3, layer type: QDense\n",
      "Layer name: relu3, layer type: QActivation\n",
      "Layer name: output, layer type: QDense\n",
      "Layer name: softmax, layer type: Activation\n",
      "Interpreting Sequential\n",
      "Topology:\n",
      "Layer name: fc1_input, layer type: InputLayer, input shapes: [[None, 16]], output shape: [None, 16]\n",
      "Layer name: fc1, layer type: QDense, input shapes: [[None, 16]], output shape: [None, 64]\n",
      "Layer name: relu1, layer type: Activation, input shapes: [[None, 64]], output shape: [None, 64]\n",
      "Layer name: fc2, layer type: QDense, input shapes: [[None, 16]], output shape: [None, 32]\n",
      "Layer name: relu2, layer type: Activation, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: fc3, layer type: QDense, input shapes: [[None, 16]], output shape: [None, 32]\n",
      "Layer name: relu3, layer type: Activation, input shapes: [[None, 32]], output shape: [None, 32]\n",
      "Layer name: output, layer type: QDense, input shapes: [[None, 32]], output shape: [None, 5]\n",
      "Layer name: softmax, layer type: Softmax, input shapes: [[None, 5]], output shape: [None, 5]\n",
      "Creating HLS model\n",
      "WARNING: Invalid ReuseFactor=1 with \"Resource\" strategy in layer \"fc1\". Using ReuseFactor=2 instead. Valid ReuseFactor(s): 2,4,8,16,32,64,128,256,512,1024.\n",
      "WARNING: Invalid ReuseFactor=1 with \"Resource\" strategy in layer \"fc2\". Using ReuseFactor=2 instead. Valid ReuseFactor(s): 2,4,8,16,32,64,128,256,512,1024,2048.\n",
      "WARNING: Invalid ReuseFactor=1 with \"Resource\" strategy in layer \"fc3\". Using ReuseFactor=2 instead. Valid ReuseFactor(s): 2,4,8,16,32,64,128,256,512,1024.\n",
      "WARNING: Invalid ReuseFactor=1 with \"Resource\" strategy in layer \"output\". Using ReuseFactor=2 instead. Valid ReuseFactor(s): 2,4,8,16,32,160.\n",
      "Writing HLS project\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# hls4ml\n",
    "#\n",
    "import hls4ml\n",
    "hls4ml.model.optimizer.OutputRoundingSaturationMode.layers = ['Activation']\n",
    "hls4ml.model.optimizer.OutputRoundingSaturationMode.rounding_mode = 'AP_RND'\n",
    "hls4ml.model.optimizer.OutputRoundingSaturationMode.saturation_mode = 'AP_SAT'\n",
    "hls_config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
    "\n",
    "hls_config['Model'] = {}\n",
    "hls_config['Model']['ReuseFactor'] = 64\n",
    "hls_config['Model']['Strategy'] = 'Resource'\n",
    "hls_config['Model']['Precision'] = 'ap_fixed<16,6>'\n",
    "hls_config['LayerName']['fc1']['ReuseFactor'] = 64\n",
    "hls_config['LayerName']['fc2']['ReuseFactor'] = 64\n",
    "hls_config['LayerName']['fc3']['ReuseFactor'] = 64\n",
    "\n",
    "hls_config['SkipOptimizers'] = ['relu_merge']\n",
    "\n",
    "hls_model = convert_from_keras_model(model=model,\n",
    "                                     clock_period=CLOCK_PERIOD,\n",
    "                                     backend='VivadoAccelerator',\n",
    "                                     board=BOARD_NAME,\n",
    "                                     part=FPGA_PART,\n",
    "                                     io_type='io_stream',\n",
    "                                     interface='axi_master',\n",
    "                                     driver='c',\n",
    "                                     hls_config=hls_config,\n",
    "                                     output_dir='model')\n",
    "\n",
    "_ = hls_model.compile()\n",
    "\n",
    "y_hls = hls_model.predict(np.ascontiguousarray(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a87cec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Keras  Accuracy: 0.7562831325301205\n",
      "hls4ml Accuracy: 0.7560361445783133\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('-----------------------------------')\n",
    "print('Keras  Accuracy: {}'.format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_keras, axis=1))))\n",
    "print('hls4ml Accuracy: {}'.format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_hls, axis=1))))\n",
    "print('-----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7191dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "****** Vivado(TM) HLS - High-Level Synthesis from C, C++ and SystemC v2019.1 (64-bit)\n",
      "  **** SW Build 2552052 on Fri May 24 14:47:09 MDT 2019\n",
      "  **** IP Build 2548770 on Fri May 24 18:01:18 MDT 2019\n",
      "    ** Copyright 1986-2019 Xilinx, Inc. All Rights Reserved.\n",
      "\n",
      "source /home/bcilab/Xilinx/Vivado/2019.1/scripts/vivado_hls/hls.tcl -notrace\n",
      "INFO: Applying HLS Y2K22 patch v1.2 for IP revision\n",
      "INFO: [HLS 200-10] Running '/home/bcilab/Xilinx/Vivado/2019.1/bin/unwrapped/lnx64.o/vivado_hls'\n",
      "INFO: [HLS 200-10] For user 'bcilab' on host 'bcilab-rrid411' (Linux_x86_64 version 4.15.0-189-generic) on Wed Jul 27 13:17:16 IST 2022\n",
      "INFO: [HLS 200-10] On os Ubuntu 18.04.6 LTS\n",
      "INFO: [HLS 200-10] In directory '/home/bcilab/NN_fpga/guissepe_notebook/model'\n",
      "Sourcing Tcl script 'build_prj.tcl'\n",
      "INFO: [HLS 200-10] Opening project '/home/bcilab/NN_fpga/guissepe_notebook/model/myproject_prj'.\n",
      "INFO: [HLS 200-10] Adding design file 'firmware/myproject_axi.cpp' to the project\n",
      "INFO: [HLS 200-10] Adding design file 'firmware/myproject.cpp' to the project\n",
      "INFO: [HLS 200-10] Adding test bench file 'myproject_test.cpp' to the project\n",
      "INFO: [HLS 200-10] Adding test bench file 'firmware/weights' to the project\n",
      "INFO: [HLS 200-10] Adding test bench file 'tb_data' to the project\n",
      "INFO: [HLS 200-10] Opening solution '/home/bcilab/NN_fpga/guissepe_notebook/model/myproject_prj/solution1'.\n",
      "INFO: [SYN 201-201] Setting up clock 'default' with a period of 10ns.\n",
      "INFO: [HLS 200-10] Setting target device to 'xczu3eg-sbva484-1-e'\n",
      "INFO: [XFORM 203-101] Allowed max sub elements number after partition is 4096.\n",
      "INFO: [XFORM 203-1161] The maximum of name length is set into 60.\n",
      "INFO: [XFORM 203-101] Allowed max sub elements number after partition is 4096.\n",
      "INFO: [XFORM 203-1161] The maximum of name length is set into 60.\n",
      "***** C/RTL SYNTHESIS *****\n",
      "INFO: [SCHED 204-61] Option 'relax_ii_for_timing' is enabled, will increase II to preserve clock frequency constraints.\n",
      "INFO: [HLS 200-10] Analyzing design file 'firmware/myproject.cpp' ... \n",
      "WARNING: [HLS 214-114] Since the only kind of statements allowed in a dataflow region are variable declarations and function calls, the compiler may not be able to correctly handle the region: firmware/nnet_utils/nnet_dense_latency.h:64:9\n",
      "WARNING: [HLS 214-104] Only for-loops and functions support the dataflow: firmware/nnet_utils/nnet_dense_latency.h:76:9\n",
      "WARNING: [HLS 214-114] Since the only kind of statements allowed in a dataflow region are variable declarations and function calls, the compiler may not be able to correctly handle the region: firmware/myproject.cpp:35:2\n",
      "WARNING: [HLS 200-471] Dataflow form checks found 3 issue(s) in file firmware/myproject.cpp\n",
      "INFO: [HLS 200-10] Analyzing design file 'firmware/myproject_axi.cpp' ... \n",
      "INFO: [HLS 200-111] Finished Linking Time (s): cpu = 00:00:28 ; elapsed = 00:00:35 . Memory (MB): peak = 896.254 ; gain = 194.969 ; free physical = 874 ; free virtual = 13257\n",
      "INFO: [HLS 200-111] Finished Checking Pragmas Time (s): cpu = 00:00:28 ; elapsed = 00:00:35 . Memory (MB): peak = 896.254 ; gain = 194.969 ; free physical = 874 ; free virtual = 13257\n",
      "INFO: [HLS 200-10] Starting code transformations ...\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>::operator[]' into 'myproject_axi' (firmware/myproject_axi.cpp:25).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>::operator[]' into 'nnet::dense<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 64u>, config2>' (firmware/nnet_utils/nnet_dense_stream.h:48).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>::operator[].1' into 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>::operator=' (firmware/nnet_utils/nnet_types.h:34).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::product::mult<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<6, 1, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::product' into 'nnet::dense_resource_rf_leq_nin<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' (firmware/nnet_utils/nnet_dense_resource.h:76).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::dense_resource_rf_leq_nin<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' into 'nnet::dense_resource<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' (firmware/nnet_utils/nnet_dense_resource.h:524).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::dense_resource<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' into 'nnet::dense_wrapper<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' (firmware/nnet_utils/nnet_dense_stream.h:24).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 64u>::operator[]' into 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 64u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 64u>, linear_config3>' (firmware/nnet_utils/nnet_activation_stream.h:47).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 64u>::operator[]' into 'nnet::dense<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 64u>, config2>' (firmware/nnet_utils/nnet_dense_stream.h:62).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 64u>::operator[].1' into 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 64u>::operator=' (firmware/nnet_utils/nnet_types.h:34).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 64u>::operator[]' into 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 64u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 64u>, relu_config4>' (firmware/nnet_utils/nnet_activation_stream.h:69).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 64u>::operator[]' into 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 64u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 64u>, relu_config4>' (firmware/nnet_utils/nnet_activation_stream.h:69).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 64u>::operator[]' into 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 64u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 64u>, linear_config3>' (firmware/nnet_utils/nnet_activation_stream.h:47).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 64u>::operator[].1' into 'nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 64u>::operator=' (firmware/nnet_utils/nnet_types.h:34).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 64u>::operator[]' into 'nnet::dense<nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 64u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>, config5>' (firmware/nnet_utils/nnet_dense_stream.h:48).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 64u>::operator[]' into 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 64u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 64u>, relu_config4>' (firmware/nnet_utils/nnet_activation_stream.h:70).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 64u>::operator[]' into 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 64u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 64u>, relu_config4>' (firmware/nnet_utils/nnet_activation_stream.h:69).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 64u>::operator[].1' into 'nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 64u>::operator=' (firmware/nnet_utils/nnet_types.h:34).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::product::mult<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<6, 1, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::product' into 'nnet::dense_resource_rf_leq_nin<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config5>' (firmware/nnet_utils/nnet_dense_resource.h:76).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::product::mult<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<6, 1, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::product' into 'nnet::dense_resource_rf_leq_nin<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config8>' (firmware/nnet_utils/nnet_dense_resource.h:76).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::product::mult<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<6, 1, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0> >::product' into 'nnet::dense_resource_rf_leq_nin<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' (firmware/nnet_utils/nnet_dense_resource.h:76).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::dense_resource_rf_leq_nin<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config5>' into 'nnet::dense_resource<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config5>' (firmware/nnet_utils/nnet_dense_resource.h:524).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::dense_resource<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config5>' into 'nnet::dense_wrapper<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config5>' (firmware/nnet_utils/nnet_dense_stream.h:24).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>::operator[]' into 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, linear_config9>' (firmware/nnet_utils/nnet_activation_stream.h:47).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>::operator[]' into 'nnet::dense<nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>, config8>' (firmware/nnet_utils/nnet_dense_stream.h:62).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>::operator[]' into 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, linear_config6>' (firmware/nnet_utils/nnet_activation_stream.h:47).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>::operator[]' into 'nnet::dense<nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 64u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>, config5>' (firmware/nnet_utils/nnet_dense_stream.h:62).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>::operator[].1' into 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>::operator=' (firmware/nnet_utils/nnet_types.h:34).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>::operator[]' into 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, relu_config10>' (firmware/nnet_utils/nnet_activation_stream.h:69).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>::operator[]' into 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, relu_config10>' (firmware/nnet_utils/nnet_activation_stream.h:69).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>::operator[]' into 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, linear_config9>' (firmware/nnet_utils/nnet_activation_stream.h:47).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>::operator[]' into 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, relu_config7>' (firmware/nnet_utils/nnet_activation_stream.h:69).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>::operator[]' into 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, relu_config7>' (firmware/nnet_utils/nnet_activation_stream.h:69).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>::operator[]' into 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, linear_config6>' (firmware/nnet_utils/nnet_activation_stream.h:47).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>::operator[].1' into 'nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>::operator=' (firmware/nnet_utils/nnet_types.h:34).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>::operator[]' into 'nnet::dense<nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 5u>, config11>' (firmware/nnet_utils/nnet_dense_stream.h:48).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>::operator[]' into 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, relu_config10>' (firmware/nnet_utils/nnet_activation_stream.h:70).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>::operator[]' into 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, relu_config10>' (firmware/nnet_utils/nnet_activation_stream.h:69).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>::operator[]' into 'nnet::dense<nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>, config8>' (firmware/nnet_utils/nnet_dense_stream.h:48).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>::operator[]' into 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, relu_config7>' (firmware/nnet_utils/nnet_activation_stream.h:70).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>::operator[]' into 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, relu_config7>' (firmware/nnet_utils/nnet_activation_stream.h:69).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>::operator[].1' into 'nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>::operator=' (firmware/nnet_utils/nnet_types.h:34).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::dense_resource_rf_leq_nin<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config8>' into 'nnet::dense_resource<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config8>' (firmware/nnet_utils/nnet_dense_resource.h:524).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::dense_resource<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config8>' into 'nnet::dense_wrapper<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config8>' (firmware/nnet_utils/nnet_dense_stream.h:24).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::dense_resource_rf_leq_nin<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' into 'nnet::dense_resource<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' (firmware/nnet_utils/nnet_dense_resource.h:524).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::dense_resource<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' into 'nnet::dense_wrapper<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' (firmware/nnet_utils/nnet_dense_stream.h:24).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 5u>::operator[]' into 'myproject_axi' (firmware/myproject_axi.cpp:35).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 5u>::operator[]' into 'nnet::softmax_latency<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 5u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 5u>, softmax_config13>' (firmware/nnet_utils/nnet_activation_stream.h:171).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 5u>::operator[]' into 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 5u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 5u>, linear_config12>' (firmware/nnet_utils/nnet_activation_stream.h:47).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 5u>::operator[]' into 'nnet::dense<nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 5u>, config11>' (firmware/nnet_utils/nnet_dense_stream.h:62).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 5u>::operator[].1' into 'nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 5u>::operator=' (firmware/nnet_utils/nnet_types.h:34).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 5u>::operator[]' into 'nnet::softmax_latency<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 5u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 5u>, softmax_config13>' (firmware/nnet_utils/nnet_activation_stream.h:155).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 5u>::operator[]' into 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 5u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 5u>, linear_config12>' (firmware/nnet_utils/nnet_activation_stream.h:47).\n",
      "INFO: [XFORM 203-603] Inlining function 'nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 5u>::operator[].1' into 'nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 5u>::operator=' (firmware/nnet_utils/nnet_types.h:34).\n",
      "INFO: [HLS 200-111] Finished Standard Transforms Time (s): cpu = 00:00:30 ; elapsed = 00:00:38 . Memory (MB): peak = 896.254 ; gain = 194.969 ; free physical = 816 ; free virtual = 13208\n",
      "INFO: [HLS 200-10] Checking synthesizability ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [XFORM 203-602] Inlining function 'nnet::cast<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' into 'nnet::dense_wrapper<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' (firmware/nnet_utils/nnet_dense_resource.h:99->firmware/nnet_utils/nnet_dense_resource.h:524->firmware/nnet_utils/nnet_dense_stream.h:24) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::cast<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config5>' into 'nnet::dense_wrapper<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config5>' (firmware/nnet_utils/nnet_dense_resource.h:99->firmware/nnet_utils/nnet_dense_resource.h:524->firmware/nnet_utils/nnet_dense_stream.h:24) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::cast<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config8>' into 'nnet::dense_wrapper<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config8>' (firmware/nnet_utils/nnet_dense_resource.h:99->firmware/nnet_utils/nnet_dense_resource.h:524->firmware/nnet_utils/nnet_dense_stream.h:24) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::cast<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' into 'nnet::dense_wrapper<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' (firmware/nnet_utils/nnet_dense_resource.h:99->firmware/nnet_utils/nnet_dense_resource.h:524->firmware/nnet_utils/nnet_dense_stream.h:24) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 2, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' into 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 4, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' (firmware/nnet_utils/nnet_common.h:55) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 4, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' into 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 5, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' (firmware/nnet_utils/nnet_common.h:55) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 1, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' into 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 5, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' (firmware/nnet_utils/nnet_common.h:55) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::softmax_idx_from_real_val<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, softmax_config13>' into 'nnet::softmax_latency<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 5u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 5u>, softmax_config13>' (firmware/nnet_utils/nnet_activation_stream.h:155) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 5, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' into 'nnet::softmax_latency<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 5u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 5u>, softmax_config13>' (firmware/nnet_utils/nnet_activation_stream.h:162) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::softmax_idx_from_real_val<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, softmax_config13>' into 'nnet::softmax_latency<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 5u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 5u>, softmax_config13>' (firmware/nnet_utils/nnet_activation_stream.h:164) automatically.\n",
      "WARNING: [SYNCHK 200-23] firmware/myproject_axi.cpp:35: variable-indexed range selection may cause suboptimal QoR.\n",
      "INFO: [SYNCHK 200-10] 0 error(s), 1 warning(s).\n",
      "INFO: [HLS 200-111] Finished Checking Synthesizability Time (s): cpu = 00:00:31 ; elapsed = 00:00:39 . Memory (MB): peak = 896.254 ; gain = 194.969 ; free physical = 800 ; free virtual = 13193\n",
      "WARNING: [XFORM 203-803] Cannot specify interface mode 'axis' on argument 'res.V.data.V' . This interface directive will be discarded. Please apply it on an argument of top module.\n",
      "WARNING: [XFORM 203-803] Cannot specify interface mode 'axis' on argument 'res.V.data.V' . This interface directive will be discarded. Please apply it on an argument of top module.\n",
      "WARNING: [XFORM 203-803] Cannot specify interface mode 'axis' on argument 'data_stream.V.data.V' . This interface directive will be discarded. Please apply it on an argument of top module.\n",
      "WARNING: [XFORM 203-803] Cannot specify interface mode 'axis' (firmware/myproject.cpp:32:1) on argument 'fc1_input.V.data.V' (firmware/myproject.cpp:25). This interface directive will be discarded. Please apply it on an argument of top module.\n",
      "WARNING: [XFORM 203-803] Cannot specify interface mode 'axis' (firmware/myproject.cpp:32:96) on argument 'layer13_out.V.data.V' (firmware/myproject.cpp:26). This interface directive will be discarded. Please apply it on an argument of top module.\n",
      "INFO: [XFORM 203-1101] Packing variable 'out_pack.data.V' (firmware/nnet_utils/nnet_activation_stream.h:166) into a 80-bit variable.\n",
      "INFO: [XFORM 203-1101] Packing variable 'out_data.data.V' (firmware/nnet_utils/nnet_activation_stream.h:64) into a 384-bit variable.\n",
      "INFO: [XFORM 203-1101] Packing variable 'out_data.data.V' (firmware/nnet_utils/nnet_activation_stream.h:64) into a 192-bit variable.\n",
      "INFO: [XFORM 203-1101] Packing variable 'out_data.data.V' (firmware/nnet_utils/nnet_activation_stream.h:64) into a 192-bit variable.\n",
      "INFO: [XFORM 203-1101] Packing variable 'out_data.data.V' (firmware/nnet_utils/nnet_activation_stream.h:42) into a 1024-bit variable.\n",
      "INFO: [XFORM 203-1101] Packing variable 'out_data.data.V' (firmware/nnet_utils/nnet_activation_stream.h:42) into a 80-bit variable.\n",
      "INFO: [XFORM 203-1101] Packing variable 'out_data.data.V' (firmware/nnet_utils/nnet_activation_stream.h:42) into a 512-bit variable.\n",
      "INFO: [XFORM 203-1101] Packing variable 'out_data.data.V' (firmware/nnet_utils/nnet_activation_stream.h:42) into a 512-bit variable.\n",
      "INFO: [XFORM 203-1101] Packing variable 'res_pack.data.V' (firmware/nnet_utils/nnet_dense_stream.h:58) into a 512-bit variable.\n",
      "INFO: [XFORM 203-1101] Packing variable 'res_pack.data.V' (firmware/nnet_utils/nnet_dense_stream.h:58) into a 80-bit variable.\n",
      "INFO: [XFORM 203-1101] Packing variable 'res_pack.data.V' (firmware/nnet_utils/nnet_dense_stream.h:58) into a 512-bit variable.\n",
      "INFO: [XFORM 203-1101] Packing variable 'res_pack.data.V' (firmware/nnet_utils/nnet_dense_stream.h:58) into a 1024-bit variable.\n",
      "INFO: [XFORM 203-1101] Packing variable 'ctype.data.V' (firmware/myproject_axi.cpp:22) into a 256-bit variable.\n",
      "INFO: [XFORM 203-502] Unrolling all loops for pipelining in function 'nnet::softmax_latency<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 5u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 5u>, softmax_config13>' (firmware/nnet_utils/nnet_activation_stream.h:32:59).\n",
      "INFO: [XFORM 203-502] Unrolling all loops for pipelining in function 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 64u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 64u>, relu_config4>' (firmware/nnet_utils/nnet_activation_stream.h:32:36).\n",
      "INFO: [XFORM 203-502] Unrolling all loops for pipelining in function 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, relu_config7>' (firmware/nnet_utils/nnet_activation_stream.h:32:36).\n",
      "INFO: [XFORM 203-502] Unrolling all loops for pipelining in function 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, relu_config10>' (firmware/nnet_utils/nnet_activation_stream.h:32:36).\n",
      "INFO: [XFORM 203-502] Unrolling all loops for pipelining in function 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 64u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 64u>, linear_config3>' (firmware/nnet_utils/nnet_activation_stream.h:32:51).\n",
      "INFO: [XFORM 203-502] Unrolling all loops for pipelining in function 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 5u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 5u>, linear_config12>' (firmware/nnet_utils/nnet_activation_stream.h:32:51).\n",
      "INFO: [XFORM 203-502] Unrolling all loops for pipelining in function 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, linear_config9>' (firmware/nnet_utils/nnet_activation_stream.h:32:51).\n",
      "INFO: [XFORM 203-502] Unrolling all loops for pipelining in function 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, linear_config6>' (firmware/nnet_utils/nnet_activation_stream.h:32:51).\n",
      "INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'ReuseLoop' (firmware/nnet_utils/nnet_dense_resource.h:64) in function 'nnet::dense_wrapper<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' for pipelining.\n",
      "INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'ReuseLoop' (firmware/nnet_utils/nnet_dense_resource.h:64) in function 'nnet::dense_wrapper<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config8>' for pipelining.\n",
      "INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'ReuseLoop' (firmware/nnet_utils/nnet_dense_resource.h:64) in function 'nnet::dense_wrapper<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config5>' for pipelining.\n",
      "INFO: [XFORM 203-502] Unrolling all sub-loops inside loop 'ReuseLoop' (firmware/nnet_utils/nnet_dense_resource.h:64) in function 'nnet::dense_wrapper<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' for pipelining.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Loop-1' (firmware/nnet_utils/nnet_types.h:32) in function 'nnet::softmax_latency<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 5u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 5u>, softmax_config13>' completely with a factor of 5.\n",
      "INFO: [HLS 200-489] Unrolling loop 'SoftmaxExpPackLoop' (firmware/nnet_utils/nnet_activation_stream.h:153) in function 'nnet::softmax_latency<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 5u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 5u>, softmax_config13>' completely with a factor of 5.\n",
      "INFO: [HLS 200-489] Unrolling loop 'SoftmaxInvPackLoop' (firmware/nnet_utils/nnet_activation_stream.h:168) in function 'nnet::softmax_latency<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 5u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 5u>, softmax_config13>' completely with a factor of 5.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Loop-1' (firmware/nnet_utils/nnet_types.h:32) in function 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 64u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 64u>, relu_config4>' completely with a factor of 64.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [HLS 200-489] Unrolling loop 'ReLUPackLoop' (firmware/nnet_utils/nnet_activation_stream.h:67) in function 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 64u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 64u>, relu_config4>' completely with a factor of 64.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Loop-1' (firmware/nnet_utils/nnet_types.h:32) in function 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, relu_config7>' completely with a factor of 32.\n",
      "INFO: [HLS 200-489] Unrolling loop 'ReLUPackLoop' (firmware/nnet_utils/nnet_activation_stream.h:67) in function 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, relu_config7>' completely with a factor of 32.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Loop-1' (firmware/nnet_utils/nnet_types.h:32) in function 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, relu_config10>' completely with a factor of 32.\n",
      "INFO: [HLS 200-489] Unrolling loop 'ReLUPackLoop' (firmware/nnet_utils/nnet_activation_stream.h:67) in function 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, relu_config10>' completely with a factor of 32.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Loop-1' (firmware/nnet_utils/nnet_types.h:32) in function 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 64u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 64u>, linear_config3>' completely with a factor of 64.\n",
      "INFO: [HLS 200-489] Unrolling loop 'LinearPackLoop' (firmware/nnet_utils/nnet_activation_stream.h:45) in function 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 64u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 64u>, linear_config3>' completely with a factor of 64.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Loop-1' (firmware/nnet_utils/nnet_types.h:32) in function 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 5u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 5u>, linear_config12>' completely with a factor of 5.\n",
      "INFO: [HLS 200-489] Unrolling loop 'LinearPackLoop' (firmware/nnet_utils/nnet_activation_stream.h:45) in function 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 5u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 5u>, linear_config12>' completely with a factor of 5.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Loop-1' (firmware/nnet_utils/nnet_types.h:32) in function 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, linear_config9>' completely with a factor of 32.\n",
      "INFO: [HLS 200-489] Unrolling loop 'LinearPackLoop' (firmware/nnet_utils/nnet_activation_stream.h:45) in function 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, linear_config9>' completely with a factor of 32.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Loop-1' (firmware/nnet_utils/nnet_types.h:32) in function 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, linear_config6>' completely with a factor of 32.\n",
      "INFO: [HLS 200-489] Unrolling loop 'LinearPackLoop' (firmware/nnet_utils/nnet_activation_stream.h:45) in function 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, linear_config6>' completely with a factor of 32.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Loop-1' (firmware/nnet_utils/nnet_types.h:32) in function 'nnet::dense<nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 64u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>, config5>' completely with a factor of 64.\n",
      "INFO: [HLS 200-489] Unrolling loop 'DataPack' (firmware/nnet_utils/nnet_dense_stream.h:46) in function 'nnet::dense<nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 64u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>, config5>' completely with a factor of 64.\n",
      "INFO: [HLS 200-489] Unrolling loop 'ResPack' (firmware/nnet_utils/nnet_dense_stream.h:60) in function 'nnet::dense<nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 64u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>, config5>' completely with a factor of 32.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Loop-1' (firmware/nnet_utils/nnet_types.h:32) in function 'nnet::dense<nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 5u>, config11>' completely with a factor of 32.\n",
      "INFO: [HLS 200-489] Unrolling loop 'DataPack' (firmware/nnet_utils/nnet_dense_stream.h:46) in function 'nnet::dense<nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 5u>, config11>' completely with a factor of 32.\n",
      "INFO: [HLS 200-489] Unrolling loop 'ResPack' (firmware/nnet_utils/nnet_dense_stream.h:60) in function 'nnet::dense<nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 5u>, config11>' completely with a factor of 5.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Loop-1' (firmware/nnet_utils/nnet_types.h:32) in function 'nnet::dense<nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>, config8>' completely with a factor of 32.\n",
      "INFO: [HLS 200-489] Unrolling loop 'DataPack' (firmware/nnet_utils/nnet_dense_stream.h:46) in function 'nnet::dense<nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>, config8>' completely with a factor of 32.\n",
      "INFO: [HLS 200-489] Unrolling loop 'ResPack' (firmware/nnet_utils/nnet_dense_stream.h:60) in function 'nnet::dense<nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>, config8>' completely with a factor of 32.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Loop-1' (firmware/nnet_utils/nnet_types.h:32) in function 'nnet::dense<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 64u>, config2>' completely with a factor of 16.\n",
      "INFO: [HLS 200-489] Unrolling loop 'DataPack' (firmware/nnet_utils/nnet_dense_stream.h:46) in function 'nnet::dense<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 64u>, config2>' completely with a factor of 16.\n",
      "INFO: [HLS 200-489] Unrolling loop 'ResPack' (firmware/nnet_utils/nnet_dense_stream.h:60) in function 'nnet::dense<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 64u>, config2>' completely with a factor of 64.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Loop-2' (firmware/nnet_utils/nnet_types.h:32) in function 'myproject_axi' completely with a factor of 5.\n",
      "INFO: [HLS 200-489] Unrolling loop 'InitAccum' (firmware/nnet_utils/nnet_dense_resource.h:58) in function 'nnet::dense_wrapper<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' completely with a factor of 5.\n",
      "INFO: [HLS 200-489] Unrolling loop 'MultLoop' (firmware/nnet_utils/nnet_dense_resource.h:73) in function 'nnet::dense_wrapper<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' completely with a factor of 80.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Result' (firmware/nnet_utils/nnet_dense_resource.h:97) in function 'nnet::dense_wrapper<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' completely with a factor of 5.\n",
      "INFO: [HLS 200-489] Unrolling loop 'InitAccum' (firmware/nnet_utils/nnet_dense_resource.h:58) in function 'nnet::dense_wrapper<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config8>' completely with a factor of 32.\n",
      "INFO: [HLS 200-489] Unrolling loop 'MultLoop' (firmware/nnet_utils/nnet_dense_resource.h:73) in function 'nnet::dense_wrapper<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config8>' completely with a factor of 512.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Result' (firmware/nnet_utils/nnet_dense_resource.h:97) in function 'nnet::dense_wrapper<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config8>' completely with a factor of 32.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [HLS 200-489] Unrolling loop 'InitAccum' (firmware/nnet_utils/nnet_dense_resource.h:58) in function 'nnet::dense_wrapper<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config5>' completely with a factor of 32.\n",
      "INFO: [HLS 200-489] Unrolling loop 'MultLoop' (firmware/nnet_utils/nnet_dense_resource.h:73) in function 'nnet::dense_wrapper<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config5>' completely with a factor of 1024.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Result' (firmware/nnet_utils/nnet_dense_resource.h:97) in function 'nnet::dense_wrapper<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config5>' completely with a factor of 32.\n",
      "INFO: [HLS 200-489] Unrolling loop 'InitAccum' (firmware/nnet_utils/nnet_dense_resource.h:58) in function 'nnet::dense_wrapper<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' completely with a factor of 64.\n",
      "INFO: [HLS 200-489] Unrolling loop 'MultLoop' (firmware/nnet_utils/nnet_dense_resource.h:73) in function 'nnet::dense_wrapper<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' completely with a factor of 512.\n",
      "INFO: [HLS 200-489] Unrolling loop 'Result' (firmware/nnet_utils/nnet_dense_resource.h:97) in function 'nnet::dense_wrapper<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' completely with a factor of 64.\n",
      "INFO: [XFORM 203-102] Partitioning array 'tmp.data.V.23' automatically.\n",
      "INFO: [XFORM 203-102] Partitioning array 'tmp.data.V.9' automatically.\n",
      "INFO: [XFORM 203-102] Partitioning array 'tmp.data.V.3' automatically.\n",
      "INFO: [XFORM 203-102] Partitioning array 'tmp.data.V.17' automatically.\n",
      "INFO: [XFORM 203-102] Partitioning array 'tmp.data.V.15' automatically.\n",
      "INFO: [XFORM 203-102] Partitioning array 'tmp.data.V.5' automatically.\n",
      "INFO: [XFORM 203-102] Partitioning array 'tmp.data.V.21' automatically.\n",
      "INFO: [XFORM 203-102] Partitioning array 'tmp.data.V.13' automatically.\n",
      "INFO: [XFORM 203-102] Partitioning array 'tmp.data.V.7' automatically.\n",
      "INFO: [XFORM 203-102] Partitioning array 'tmp.data.V.19' automatically.\n",
      "INFO: [XFORM 203-102] Partitioning array 'tmp.data.V.11' automatically.\n",
      "INFO: [XFORM 203-102] Partitioning array 'tmp.data.V.1' automatically.\n",
      "INFO: [XFORM 203-131] Reshaping array 'w11.V'  in dimension 1 with a block factor of 80.\n",
      "INFO: [XFORM 203-131] Reshaping array 'w8.V'  in dimension 1 with a block factor of 512.\n",
      "INFO: [XFORM 203-131] Reshaping array 'w5.V'  in dimension 1 with a block factor of 1024.\n",
      "INFO: [XFORM 203-131] Reshaping array 'w2.V'  in dimension 1 with a block factor of 512.\n",
      "INFO: [XFORM 203-102] Automatically partitioning streamed array 'layer12_out.V.data.V' (firmware/myproject.cpp:100) .\n",
      "INFO: [XFORM 203-102] Automatically partitioning streamed array 'out_local.V.data.V' (firmware/myproject_axi.cpp:16) .\n",
      "INFO: [XFORM 203-102] Automatically partitioning streamed array 'layer3_out.V.data.V' (firmware/myproject.cpp:64) .\n",
      "INFO: [XFORM 203-102] Automatically partitioning streamed array 'layer4_out.V.data.V' (firmware/myproject.cpp:68) .\n",
      "INFO: [XFORM 203-102] Automatically partitioning streamed array 'layer6_out.V.data.V' (firmware/myproject.cpp:76) .\n",
      "INFO: [XFORM 203-102] Automatically partitioning streamed array 'layer7_out.V.data.V' (firmware/myproject.cpp:80) .\n",
      "INFO: [XFORM 203-102] Automatically partitioning streamed array 'layer9_out.V.data.V' (firmware/myproject.cpp:88) .\n",
      "INFO: [XFORM 203-102] Automatically partitioning streamed array 'layer10_out.V.data.V' (firmware/myproject.cpp:92) .\n",
      "INFO: [XFORM 203-102] Automatically partitioning streamed array 'layer2_out.V.data.V' (firmware/myproject.cpp:60) .\n",
      "INFO: [XFORM 203-102] Automatically partitioning streamed array 'layer11_out.V.data.V' (firmware/myproject.cpp:96) .\n",
      "INFO: [XFORM 203-102] Automatically partitioning streamed array 'layer8_out.V.data.V' (firmware/myproject.cpp:84) .\n",
      "INFO: [XFORM 203-102] Automatically partitioning streamed array 'layer5_out.V.data.V' (firmware/myproject.cpp:72) .\n",
      "INFO: [XFORM 203-102] Automatically partitioning streamed array 'in_local.V.data.V' (firmware/myproject_axi.cpp:15) .\n",
      "INFO: [XFORM 203-101] Partitioning array 'exp_res.V' (firmware/nnet_utils/nnet_activation_stream.h:146) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'tmp.data.V.2' in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'tmp.data.V.4' in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'tmp.data.V.6' in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'tmp.data.V.8' in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'tmp.data.V.10' in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'tmp.data.V.12' in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'tmp.data.V.14' in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'tmp.data.V.16' in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'data.V' (firmware/nnet_utils/nnet_dense_stream.h:35) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'res'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'tmp.data.V.18' in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'data.V' (firmware/nnet_utils/nnet_dense_stream.h:35) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'res'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'tmp.data.V.20' in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'data.V' (firmware/nnet_utils/nnet_dense_stream.h:35) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'res'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'tmp.data.V.22' in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'data.V' (firmware/nnet_utils/nnet_dense_stream.h:35) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'res'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'tmp.data.V.24' in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'tmp.data.V.28' in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'b11.V'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'acc.V' (firmware/nnet_utils/nnet_dense_resource.h:54) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'b8.V'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'acc.V' (firmware/nnet_utils/nnet_dense_resource.h:54) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'b5.V'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'acc.V' (firmware/nnet_utils/nnet_dense_resource.h:54) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'b2.V'  in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'acc.V' (firmware/nnet_utils/nnet_dense_resource.h:54) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'layer12_out.V.data.V' (firmware/myproject.cpp:100) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'out_local.V.data.V' (firmware/myproject_axi.cpp:16) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'layer3_out.V.data.V' (firmware/myproject.cpp:64) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'layer4_out.V.data.V' (firmware/myproject.cpp:68) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'layer6_out.V.data.V' (firmware/myproject.cpp:76) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'layer7_out.V.data.V' (firmware/myproject.cpp:80) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'layer9_out.V.data.V' (firmware/myproject.cpp:88) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'layer10_out.V.data.V' (firmware/myproject.cpp:92) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'layer2_out.V.data.V' (firmware/myproject.cpp:60) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'layer11_out.V.data.V' (firmware/myproject.cpp:96) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'layer8_out.V.data.V' (firmware/myproject.cpp:84) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'layer5_out.V.data.V' (firmware/myproject.cpp:72) in dimension 1 completely.\n",
      "INFO: [XFORM 203-101] Partitioning array 'in_local.V.data.V' (firmware/myproject_axi.cpp:15) in dimension 1 completely.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: [XFORM 203-104] Completely partitioning array 'data.V' (firmware/nnet_utils/nnet_dense_stream.h:35) accessed through non-constant indices on dimension 1 (firmware/nnet_utils/nnet_dense_resource.h:76:20), which may result in long runtime and suboptimal QoR due to large multiplexers. Please consider wrapping the array access into a function or using a register file core instead.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::cast<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' into 'nnet::dense_wrapper<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' (firmware/nnet_utils/nnet_dense_resource.h:99->firmware/nnet_utils/nnet_dense_resource.h:524->firmware/nnet_utils/nnet_dense_stream.h:24) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::cast<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config5>' into 'nnet::dense_wrapper<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config5>' (firmware/nnet_utils/nnet_dense_resource.h:99->firmware/nnet_utils/nnet_dense_resource.h:524->firmware/nnet_utils/nnet_dense_stream.h:24) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::cast<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config8>' into 'nnet::dense_wrapper<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config8>' (firmware/nnet_utils/nnet_dense_resource.h:99->firmware/nnet_utils/nnet_dense_resource.h:524->firmware/nnet_utils/nnet_dense_stream.h:24) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::cast<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' into 'nnet::dense_wrapper<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' (firmware/nnet_utils/nnet_dense_resource.h:99->firmware/nnet_utils/nnet_dense_resource.h:524->firmware/nnet_utils/nnet_dense_stream.h:24) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> >::operator()' into 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 2, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' (firmware/nnet_utils/nnet_common.h:53) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> >::operator()' into 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 4, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' (firmware/nnet_utils/nnet_common.h:55) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 4, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' into 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 5, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' (firmware/nnet_utils/nnet_common.h:55) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 1, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' into 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 5, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' (firmware/nnet_utils/nnet_common.h:55) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> >::operator()' into 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 5, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' (firmware/nnet_utils/nnet_common.h:55) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::softmax_idx_from_real_val<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, softmax_config13>' into 'nnet::softmax_latency<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 5u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 5u>, softmax_config13>' (firmware/nnet_utils/nnet_activation_stream.h:155) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::softmax_idx_from_real_val<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, softmax_config13>' into 'nnet::softmax_latency<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 5u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 5u>, softmax_config13>' (firmware/nnet_utils/nnet_activation_stream.h:164) automatically.\n",
      "INFO: [XFORM 203-712] Applying dataflow to function 'myproject', detected/extracted 13 process function(s): \n",
      "\t 'myproject_Block__proc'\n",
      "\t 'nnet::dense<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 64u>, config2>'\n",
      "\t 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 64u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 64u>, linear_config3>'\n",
      "\t 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 64u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 64u>, relu_config4>'\n",
      "\t 'nnet::dense<nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 64u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>, config5>'\n",
      "\t 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, linear_config6>'\n",
      "\t 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, relu_config7>'\n",
      "\t 'nnet::dense<nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>, config8>'\n",
      "\t 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, linear_config9>'\n",
      "\t 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, relu_config10>'\n",
      "\t 'nnet::dense<nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 5u>, config11>'\n",
      "\t 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 5u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 5u>, linear_config12>'\n",
      "\t 'nnet::softmax<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 5u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 5u>, softmax_config13>'.\n",
      "INFO: [XFORM 203-401] Performing if-conversion on hyperblock to (firmware/nnet_utils/nnet_activation_stream.h:75:1) in function 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 64u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 64u>, relu_config4>'... converting 193 basic blocks.\n",
      "INFO: [XFORM 203-401] Performing if-conversion on hyperblock to (firmware/nnet_utils/nnet_activation_stream.h:75:1) in function 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, relu_config7>'... converting 97 basic blocks.\n",
      "INFO: [XFORM 203-401] Performing if-conversion on hyperblock to (firmware/nnet_utils/nnet_activation_stream.h:75:1) in function 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, relu_config10>'... converting 97 basic blocks.\n",
      "INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (firmware/nnet_utils/nnet_common.h:45:20) to (firmware/nnet_utils/nnet_common.h:55:43) in function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 5, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >'... converting 9 basic blocks.\n",
      "INFO: [XFORM 203-401] Performing if-conversion on hyperblock to (firmware/nnet_utils/nnet_common.h:53:17) in function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 2, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >'... converting 5 basic blocks.\n",
      "INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (firmware/myproject_axi.cpp:25:13) to (firmware/myproject_axi.cpp:24:41) in function 'myproject_axi'... converting 10 basic blocks.\n",
      "INFO: [XFORM 203-401] Performing if-conversion on hyperblock from (firmware/myproject_axi.cpp:35:56) to (firmware/myproject_axi.cpp:34:49) in function 'myproject_axi'... converting 10 basic blocks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 2, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' into 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 5, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' (firmware/nnet_utils/nnet_common.h:55->firmware/nnet_utils/nnet_common.h:55) automatically.\n",
      "INFO: [XFORM 203-602] Inlining function 'nnet::reduce<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0>, 5, nnet::Op_add<ap_fixed<18, 8, (ap_q_mode)0, (ap_o_mode)0, 0> > >' into 'nnet::softmax_latency<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 5u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 5u>, softmax_config13>' (firmware/nnet_utils/nnet_activation_stream.h:162) automatically.\n",
      "INFO: [XFORM 203-11] Balancing expressions in function 'nnet::dense_wrapper<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config8>' (firmware/nnet_utils/nnet_mult.h:24:9)...512 expression(s) balanced.\n",
      "INFO: [XFORM 203-11] Balancing expressions in function 'nnet::dense_wrapper<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config5>' (firmware/nnet_utils/nnet_mult.h:24:9)...1024 expression(s) balanced.\n",
      "INFO: [XFORM 203-11] Balancing expressions in function 'nnet::dense_wrapper<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' (firmware/nnet_utils/nnet_mult.h:24:9)...80 expression(s) balanced.\n",
      "INFO: [XFORM 203-11] Balancing expressions in function 'nnet::dense_wrapper<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' (firmware/nnet_utils/nnet_mult.h:24:9)...512 expression(s) balanced.\n",
      "INFO: [HLS 200-111] Finished Pre-synthesis Time (s): cpu = 00:04:25 ; elapsed = 00:04:32 . Memory (MB): peak = 1024.254 ; gain = 322.969 ; free physical = 602 ; free virtual = 13022\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::softmax_latency<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 5u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 5u>, softmax_config13>' to 'softmax_latency<array,array,softmax_config13>' (firmware/nnet_utils/nnet_activation_stream.h:34:1)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::softmax<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 5u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 5u>, softmax_config13>' to 'softmax<array,array<ap_fixed,5u>,softmax_config13>' (firmware/nnet_utils/nnet_activation_stream.h:323:1)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 64u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 64u>, relu_config4>' to 'relu<array,array<ap_ufixed,64u>,relu_config4>' (firmware/nnet_utils/nnet_activation_stream.h:34:6)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, relu_config7>' to 'relu<array,array<ap_ufixed,32u>,relu_config7>' (firmware/nnet_utils/nnet_activation_stream.h:34:9)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::relu<nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, relu_config10>' to 'relu<array,array<ap_ufixed,32u>,relu_config10>' (firmware/nnet_utils/nnet_activation_stream.h:34:9)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 64u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 64u>, linear_config3>' to 'linear<array,array<ap_fixed,64u>,linear_config3>' (firmware/nnet_utils/nnet_activation_stream.h:34:1)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 5u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 5u>, linear_config12>' to 'linear<array,array<ap_fixed,5u>,linear_config12>' (firmware/nnet_utils/nnet_activation_stream.h:34:1)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, linear_config9>' to 'linear<array,array<ap_fixed,32u>,linear_config9>' (firmware/nnet_utils/nnet_activation_stream.h:34:1)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::linear<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, linear_config6>' to 'linear<array,array<ap_fixed,32u>,linear_config6>' (firmware/nnet_utils/nnet_activation_stream.h:34:1)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::dense_wrapper<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config8>' to 'dense_wrapper<ap_ufixed,ap_fixed<16,6,5,3,0>,config8>' (firmware/nnet_utils/nnet_mult.h:24:9)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::dense_wrapper<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config5>' to 'dense_wrapper<ap_ufixed,ap_fixed<16,6,5,3,0>,config5>' (firmware/nnet_utils/nnet_dense_resource.h:24:20)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::dense_wrapper<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config11>' to 'dense_wrapper<ap_ufixed,ap_fixed<16,6,5,3,0>,config11>' (firmware/nnet_utils/nnet_mult.h:24:9)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::dense_wrapper<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, config2>' to 'dense_wrapper<ap_fixed,ap_fixed<16,6,5,3,0>,config2>' (firmware/nnet_utils/nnet_mult.h:24:9)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::dense<nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 64u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>, config5>' to 'dense<array,array<ap_fixed<16,6,5,3,0>,32u>,config5>' (firmware/nnet_utils/nnet_dense_stream.h:34:1)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::dense<nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 5u>, config11>' to 'dense<array,array<ap_fixed<16,6,5,3,0>,5u>,config11>' (firmware/nnet_utils/nnet_dense_stream.h:34:1)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::dense<nnet::array<ap_ufixed<6, 0, (ap_q_mode)0, (ap_o_mode)0, 0>, 32u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 32u>, config8>' to 'dense<array,array<ap_fixed<16,6,5,3,0>,32u>,config8>' (firmware/nnet_utils/nnet_dense_stream.h:34:1)\n",
      "WARNING: [XFORM 203-631] Renaming function 'nnet::dense<nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 16u>, nnet::array<ap_fixed<16, 6, (ap_q_mode)5, (ap_o_mode)3, 0>, 64u>, config2>' to 'dense<array,array<ap_fixed<16,6,5,3,0>,64u>,config2>' (firmware/nnet_utils/nnet_dense_stream.h:34:1)\n",
      "INFO: [HLS 200-444] Inferring multiple bus burst read of a total cumulative length 16 on port 'IN_BUS' (firmware/myproject_axi.cpp:25:13). These data requests might be further partitioned to multiple requests during RTL generation, based on max_read_burst_length or max_write_burst_length settings.\n",
      "INFO: [HLS 200-444] Inferring multiple bus burst write of a total cumulative length 5 on port 'OUT_BUS' (firmware/myproject_axi.cpp:35:56). These data requests might be further partitioned to multiple requests during RTL generation, based on max_read_burst_length or max_write_burst_length settings.\n",
      "INFO: [XFORM 203-531] Rewinding loop 'ReuseLoop' (firmware/nnet_utils/nnet_dense_resource.h:64) in function 'dense_wrapper<ap_ufixed,ap_fixed<16,6,5,3,0>,config8>'.\n",
      "INFO: [XFORM 203-531] Rewinding loop 'ReuseLoop' (firmware/nnet_utils/nnet_dense_resource.h:64) in function 'dense_wrapper<ap_ufixed,ap_fixed<16,6,5,3,0>,config5>'.\n",
      "INFO: [XFORM 203-531] Rewinding loop 'ReuseLoop' (firmware/nnet_utils/nnet_dense_resource.h:64) in function 'dense_wrapper<ap_ufixed,ap_fixed<16,6,5,3,0>,config11>'.\n",
      "INFO: [XFORM 203-531] Rewinding loop 'ReuseLoop' (firmware/nnet_utils/nnet_dense_resource.h:64) in function 'dense_wrapper<ap_fixed,ap_fixed<16,6,5,3,0>,config2>'.\n",
      "WARNING: [XFORM 203-561] Ignored multiple trip count directives for loop 'ReuseLoop' in function 'dense_wrapper<ap_ufixed,ap_fixed<16,6,5,3,0>,config8>'.\n",
      "WARNING: [XFORM 203-561] Ignored multiple trip count directives for loop 'ReuseLoop' in function 'dense_wrapper<ap_ufixed,ap_fixed<16,6,5,3,0>,config5>'.\n",
      "WARNING: [XFORM 203-561] Ignored multiple trip count directives for loop 'ReuseLoop' in function 'dense_wrapper<ap_ufixed,ap_fixed<16,6,5,3,0>,config11>'.\n",
      "WARNING: [XFORM 203-561] Ignored multiple trip count directives for loop 'ReuseLoop' in function 'dense_wrapper<ap_fixed,ap_fixed<16,6,5,3,0>,config2>'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [HLS 200-111] Finished Architecture Synthesis Time (s): cpu = 00:05:34 ; elapsed = 00:05:41 . Memory (MB): peak = 1280.254 ; gain = 578.969 ; free physical = 465 ; free virtual = 12882\n",
      "INFO: [HLS 200-10] Starting hardware synthesis ...\n",
      "INFO: [HLS 200-10] Synthesizing 'myproject_axi' ...\n",
      "WARNING: [SYN 201-103] Legalizing function name 'dense_wrapper<ap_fixed,ap_fixed<16,6,5,3,0>,config2>' to 'dense_wrapper_ap_fixed_ap_fixed_16_6_5_3_0_config2_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'dense<array,array<ap_fixed<16,6,5,3,0>,64u>,config2>' to 'dense_array_array_ap_fixed_16_6_5_3_0_64u_config2_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'linear<array,array<ap_fixed,64u>,linear_config3>' to 'linear_array_array_ap_fixed_64u_linear_config3_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'relu<array,array<ap_ufixed,64u>,relu_config4>' to 'relu_array_array_ap_ufixed_64u_relu_config4_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'dense_wrapper<ap_ufixed,ap_fixed<16,6,5,3,0>,config5>' to 'dense_wrapper_ap_ufixed_ap_fixed_16_6_5_3_0_config5_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'dense<array,array<ap_fixed<16,6,5,3,0>,32u>,config5>' to 'dense_array_array_ap_fixed_16_6_5_3_0_32u_config5_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'linear<array,array<ap_fixed,32u>,linear_config6>' to 'linear_array_array_ap_fixed_32u_linear_config6_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'relu<array,array<ap_ufixed,32u>,relu_config7>' to 'relu_array_array_ap_ufixed_32u_relu_config7_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'dense_wrapper<ap_ufixed,ap_fixed<16,6,5,3,0>,config8>' to 'dense_wrapper_ap_ufixed_ap_fixed_16_6_5_3_0_config8_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'dense<array,array<ap_fixed<16,6,5,3,0>,32u>,config8>' to 'dense_array_array_ap_fixed_16_6_5_3_0_32u_config8_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'linear<array,array<ap_fixed,32u>,linear_config9>' to 'linear_array_array_ap_fixed_32u_linear_config9_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'relu<array,array<ap_ufixed,32u>,relu_config10>' to 'relu_array_array_ap_ufixed_32u_relu_config10_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'dense_wrapper<ap_ufixed,ap_fixed<16,6,5,3,0>,config11>' to 'dense_wrapper_ap_ufixed_ap_fixed_16_6_5_3_0_config11_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'dense<array,array<ap_fixed<16,6,5,3,0>,5u>,config11>' to 'dense_array_array_ap_fixed_16_6_5_3_0_5u_config11_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'linear<array,array<ap_fixed,5u>,linear_config12>' to 'linear_array_array_ap_fixed_5u_linear_config12_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'softmax_latency<array,array,softmax_config13>' to 'softmax_latency_array_array_softmax_config13_s'.\n",
      "WARNING: [SYN 201-103] Legalizing function name 'softmax<array,array<ap_fixed,5u>,softmax_config13>' to 'softmax_array_array_ap_fixed_5u_softmax_config13_s'.\n",
      "WARNING: [SYN 201-107] Renaming port name 'myproject_axi/in' to 'myproject_axi/in_r' to avoid the conflict with HDL keywords or other object names.\n",
      "WARNING: [SYN 201-107] Renaming port name 'myproject_axi/out' to 'myproject_axi/out_r' to avoid the conflict with HDL keywords or other object names.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'dense_wrapper_ap_fixed_ap_fixed_16_6_5_3_0_config2_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining loop 'ReuseLoop'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 2.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 343.16 seconds; current allocated memory: 537.976 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 4.89 seconds; current allocated memory: 549.058 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'dense_array_array_ap_fixed_16_6_5_3_0_64u_config2_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 4.2 seconds; current allocated memory: 549.769 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.34 seconds; current allocated memory: 550.846 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'linear_array_array_ap_fixed_64u_linear_config3_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'linear<array,array<ap_fixed,64u>,linear_config3>'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 1.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.62 seconds; current allocated memory: 551.405 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.27 seconds; current allocated memory: 552.660 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'relu_array_array_ap_ufixed_64u_relu_config4_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'relu<array,array<ap_ufixed,64u>,relu_config4>'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 1.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.55 seconds; current allocated memory: 556.147 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 1.82 seconds; current allocated memory: 562.248 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'dense_wrapper_ap_ufixed_ap_fixed_16_6_5_3_0_config5_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining loop 'ReuseLoop'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 2.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 7.22 seconds; current allocated memory: 589.108 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 16.51 seconds; current allocated memory: 614.784 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'dense_array_array_ap_fixed_16_6_5_3_0_32u_config5_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 12.01 seconds; current allocated memory: 618.366 MB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.93 seconds; current allocated memory: 620.554 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'linear_array_array_ap_fixed_32u_linear_config6_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'linear<array,array<ap_fixed,32u>,linear_config6>'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 1.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 2.32 seconds; current allocated memory: 623.613 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.14 seconds; current allocated memory: 624.266 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'relu_array_array_ap_ufixed_32u_relu_config7_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'relu<array,array<ap_ufixed,32u>,relu_config7>'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 1.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.3 seconds; current allocated memory: 626.034 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.92 seconds; current allocated memory: 628.869 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'dense_wrapper_ap_ufixed_ap_fixed_16_6_5_3_0_config8_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining loop 'ReuseLoop'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 2.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 3.38 seconds; current allocated memory: 642.439 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 6.94 seconds; current allocated memory: 655.553 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'dense_array_array_ap_fixed_16_6_5_3_0_32u_config8_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 6.1 seconds; current allocated memory: 657.413 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.54 seconds; current allocated memory: 658.659 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'linear_array_array_ap_fixed_32u_linear_config9_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'linear<array,array<ap_fixed,32u>,linear_config9>'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 1.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 1.26 seconds; current allocated memory: 660.337 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.15 seconds; current allocated memory: 660.992 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'relu_array_array_ap_ufixed_32u_relu_config10_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'relu<array,array<ap_ufixed,32u>,relu_config10>'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 1.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.32 seconds; current allocated memory: 662.760 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.91 seconds; current allocated memory: 665.619 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'dense_wrapper_ap_ufixed_ap_fixed_16_6_5_3_0_config11_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining loop 'ReuseLoop'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 2.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 1.46 seconds; current allocated memory: 668.431 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 1.06 seconds; current allocated memory: 671.096 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'dense_array_array_ap_fixed_16_6_5_3_0_5u_config11_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 1.18 seconds; current allocated memory: 671.599 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.18 seconds; current allocated memory: 672.149 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'linear_array_array_ap_fixed_5u_linear_config12_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-61] Pipelining function 'linear<array,array<ap_fixed,5u>,linear_config12>'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 1.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.35 seconds; current allocated memory: 672.478 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.05 seconds; current allocated memory: 672.628 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'softmax_latency_array_array_softmax_config13_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [SCHED 204-61] Pipelining function 'softmax_latency<array,array,softmax_config13>'.\n",
      "INFO: [SCHED 204-61] Pipelining result : Target II = 1, Final II = 1, Depth = 3.\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.12 seconds; current allocated memory: 672.988 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Starting global binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.2 seconds; current allocated memory: 673.461 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'softmax_array_array_ap_fixed_5u_softmax_config13_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.22 seconds; current allocated memory: 673.563 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.05 seconds; current allocated memory: 673.688 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'myproject' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.24 seconds; current allocated memory: 675.746 MB.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 12.08 seconds; current allocated memory: 696.789 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-42] -- Implementing module 'myproject_axi' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SCHED 204-11] Starting scheduling ...\n",
      "INFO: [SCHED 204-11] Finished scheduling.\n",
      "INFO: [HLS 200-111]  Elapsed time: 6.19 seconds; current allocated memory: 703.371 MB.\n",
      "INFO: [HLS 200-434] Only 0 loops out of a total 2 loops have been pipelined in this design.\n",
      "INFO: [BIND 205-100] Starting micro-architecture generation ...\n",
      "INFO: [BIND 205-101] Performing variable lifetime analysis.\n",
      "INFO: [BIND 205-101] Exploring resource sharing.\n",
      "INFO: [BIND 205-101] Binding ...\n",
      "INFO: [BIND 205-100] Finished micro-architecture generation.\n",
      "INFO: [HLS 200-111]  Elapsed time: 1.92 seconds; current allocated memory: 706.593 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'dense_wrapper_ap_fixed_ap_fixed_16_6_5_3_0_config2_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-104] Estimated max fanout for 'dense_wrapper_ap_fixed_ap_fixed_16_6_5_3_0_config2_s' is 8180 from HDL expression: ((1'b0 == ap_block_pp0_stage0) & (ap_enable_reg_pp0_iter1 == 1'b1) & (1'b1 == ap_CS_fsm_pp0_stage0))\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_axi_mul_mul_6s_16s_21_1_1': 510 instance(s).\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'dense_wrapper_ap_fixed_ap_fixed_16_6_5_3_0_config2_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 5.72 seconds; current allocated memory: 743.856 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'dense_array_array_ap_fixed_16_6_5_3_0_64u_config2_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'dense_array_array_ap_fixed_16_6_5_3_0_64u_config2_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 6.24 seconds; current allocated memory: 795.898 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'linear_array_array_ap_fixed_64u_linear_config3_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'linear_array_array_ap_fixed_64u_linear_config3_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 1.13 seconds; current allocated memory: 804.507 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'relu_array_array_ap_ufixed_64u_relu_config4_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'relu_array_array_ap_ufixed_64u_relu_config4_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 0.92 seconds; current allocated memory: 819.763 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'dense_wrapper_ap_ufixed_ap_fixed_16_6_5_3_0_config5_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-104] Estimated max fanout for 'dense_wrapper_ap_ufixed_ap_fixed_16_6_5_3_0_config5_s' is 12276 from HDL expression: ((1'b0 == ap_block_pp0_stage0) & (ap_enable_reg_pp0_iter1 == 1'b1) & (1'b1 == ap_CS_fsm_pp0_stage0))\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'dense_wrapper_ap_ufixed_ap_fixed_16_6_5_3_0_config5_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 5.36 seconds; current allocated memory: 884.549 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'dense_array_array_ap_fixed_16_6_5_3_0_32u_config5_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'dense_array_array_ap_fixed_16_6_5_3_0_32u_config5_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 20.16 seconds; current allocated memory: 1013.531 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'linear_array_array_ap_fixed_32u_linear_config6_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'linear_array_array_ap_fixed_32u_linear_config6_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 3.95 seconds; current allocated memory: 1020.156 MB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'relu_array_array_ap_ufixed_32u_relu_config7_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'relu_array_array_ap_ufixed_32u_relu_config7_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 1.84 seconds; current allocated memory: 1.003 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'dense_wrapper_ap_ufixed_ap_fixed_16_6_5_3_0_config8_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-104] Estimated max fanout for 'dense_wrapper_ap_ufixed_ap_fixed_16_6_5_3_0_config8_s' is 6132 from HDL expression: ((1'b0 == ap_block_pp0_stage0) & (ap_enable_reg_pp0_iter1 == 1'b1) & (1'b1 == ap_CS_fsm_pp0_stage0))\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'dense_wrapper_ap_ufixed_ap_fixed_16_6_5_3_0_config8_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 3.8 seconds; current allocated memory: 1.035 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'dense_array_array_ap_fixed_16_6_5_3_0_32u_config8_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'dense_array_array_ap_fixed_16_6_5_3_0_32u_config8_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 11.11 seconds; current allocated memory: 1.099 GB.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'linear_array_array_ap_fixed_32u_linear_config9_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'linear_array_array_ap_fixed_32u_linear_config9_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 3.46 seconds; current allocated memory: 1.103 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'relu_array_array_ap_ufixed_32u_relu_config10_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'relu_array_array_ap_ufixed_32u_relu_config10_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 2.44 seconds; current allocated memory: 1.110 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'dense_wrapper_ap_ufixed_ap_fixed_16_6_5_3_0_config11_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SYN 201-210] Renamed object name 'dense_wrapper_ap_ufixed_ap_fixed_16_6_5_3_0_config11_s_w11_V' to 'dense_wrapper_ap_ufixed_ap_fixed_16_6_5_3_0_config11_s_w1bkb' due to the length limit 60\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'dense_wrapper_ap_ufixed_ap_fixed_16_6_5_3_0_config11_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 3.86 seconds; current allocated memory: 1.123 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'dense_array_array_ap_fixed_16_6_5_3_0_5u_config11_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'dense_array_array_ap_fixed_16_6_5_3_0_5u_config11_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 3.98 seconds; current allocated memory: 1.137 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'linear_array_array_ap_fixed_5u_linear_config12_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'linear_array_array_ap_fixed_5u_linear_config12_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 2.71 seconds; current allocated memory: 1.138 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'softmax_latency_array_array_softmax_config13_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SYN 201-210] Renamed object name 'softmax_latency_array_array_softmax_config13_s_invert_table8' to 'softmax_latency_array_array_softmax_config13_s_invert_tabcud' due to the length limit 60\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'softmax_latency_array_array_softmax_config13_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 2.5 seconds; current allocated memory: 1.139 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'softmax_array_array_ap_fixed_5u_softmax_config13_s' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'softmax_array_array_ap_fixed_5u_softmax_config13_s'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 2.67 seconds; current allocated memory: 1.141 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'myproject' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [SYN 201-210] Renamed object name 'start_for_dense_array_array_ap_fixed_16_6_5_3_0_32u_config5_U0' to 'start_for_dense_array_array_ap_fixed_16_6_5_3_0_32u_confidEe' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'start_for_dense_array_array_ap_fixed_16_6_5_3_0_32u_config8_U0' to 'start_for_dense_array_array_ap_fixed_16_6_5_3_0_32u_confieOg' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'start_for_dense_array_array_ap_fixed_16_6_5_3_0_5u_config11_U0' to 'start_for_dense_array_array_ap_fixed_16_6_5_3_0_5u_configfYi' due to the length limit 60\n",
      "INFO: [SYN 201-210] Renamed object name 'start_for_softmax_array_array_ap_fixed_5u_softmax_config13_U0' to 'start_for_softmax_array_array_ap_fixed_5u_softmax_config1g8j' due to the length limit 60\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'myproject'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 4.07 seconds; current allocated memory: 1.157 GB.\n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [HLS 200-10] -- Generating RTL for module 'myproject_axi' \n",
      "INFO: [HLS 200-10] ----------------------------------------------------------------\n",
      "INFO: [RTGEN 206-500] Setting interface mode on port 'myproject_axi/IN_BUS' to 'm_axi'.\n",
      "INFO: [RTGEN 206-500] Setting interface mode on port 'myproject_axi/OUT_BUS' to 'm_axi'.\n",
      "INFO: [RTGEN 206-500] Setting interface mode on port 'myproject_axi/in_r' to 's_axilite & ap_none'.\n",
      "INFO: [RTGEN 206-500] Setting interface mode on port 'myproject_axi/out_r' to 's_axilite & ap_none'.\n",
      "INFO: [RTGEN 206-500] Setting interface mode on function 'myproject_axi' to 's_axilite & ap_ctrl_hs'.\n",
      "INFO: [RTGEN 206-100] Bundling port 'return', 'in_r' and 'out_r' to AXI-Lite port CTRL_BUS.\n",
      "INFO: [RTGEN 206-100] Generating core module 'myproject_axi_fpext_32ns_64_2_1': 1 instance(s).\n",
      "INFO: [RTGEN 206-100] Finished creating RTL model for 'myproject_axi'.\n",
      "INFO: [HLS 200-111]  Elapsed time: 10.42 seconds; current allocated memory: 1.176 GB.\n",
      "INFO: [RTMG 210-279] Implementing memory 'dense_wrapper_ap_fixed_ap_fixed_16_6_5_3_0_config2_s_w2_V_rom' using auto ROMs.\n",
      "INFO: [RTMG 210-279] Implementing memory 'dense_wrapper_ap_ufixed_ap_fixed_16_6_5_3_0_config5_s_w5_V_rom' using auto ROMs.\n",
      "INFO: [RTMG 210-279] Implementing memory 'dense_wrapper_ap_ufixed_ap_fixed_16_6_5_3_0_config8_s_w8_V_rom' using auto ROMs.\n",
      "INFO: [RTMG 210-279] Implementing memory 'dense_wrapper_ap_ufixed_ap_fixed_16_6_5_3_0_config11_s_w1bkb_rom' using distributed ROMs.\n",
      "INFO: [RTMG 210-279] Implementing memory 'softmax_latency_array_array_softmax_config13_s_exp_table7_rom' using block ROMs.\n",
      "INFO: [RTMG 210-279] Implementing memory 'softmax_latency_array_array_softmax_config13_s_invert_tabcud_rom' using auto ROMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'start_for_linear_array_array_ap_fixed_64u_linear_config3_U0_U(start_for_linear_array_array_ap_fixed_64u_linear_config3_U0)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'start_for_relu_array_array_ap_ufixed_64u_relu_config4_U0_U(start_for_relu_array_array_ap_ufixed_64u_relu_config4_U0)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'start_for_dense_array_array_ap_fixed_16_6_5_3_0_32u_confidEe_U(start_for_dense_array_array_ap_fixed_16_6_5_3_0_32u_confidEe)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'start_for_linear_array_array_ap_fixed_32u_linear_config6_U0_U(start_for_linear_array_array_ap_fixed_32u_linear_config6_U0)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'start_for_relu_array_array_ap_ufixed_32u_relu_config7_U0_U(start_for_relu_array_array_ap_ufixed_32u_relu_config7_U0)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'start_for_dense_array_array_ap_fixed_16_6_5_3_0_32u_confieOg_U(start_for_dense_array_array_ap_fixed_16_6_5_3_0_32u_confieOg)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'start_for_linear_array_array_ap_fixed_32u_linear_config9_U0_U(start_for_linear_array_array_ap_fixed_32u_linear_config9_U0)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'start_for_relu_array_array_ap_ufixed_32u_relu_config10_U0_U(start_for_relu_array_array_ap_ufixed_32u_relu_config10_U0)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'start_for_dense_array_array_ap_fixed_16_6_5_3_0_5u_configfYi_U(start_for_dense_array_array_ap_fixed_16_6_5_3_0_5u_configfYi)' using Shift Registers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: [RTMG 210-285] Implementing FIFO 'start_for_linear_array_array_ap_fixed_5u_linear_config12_U0_U(start_for_linear_array_array_ap_fixed_5u_linear_config12_U0)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'start_for_softmax_array_array_ap_fixed_5u_softmax_config1g8j_U(start_for_softmax_array_array_ap_fixed_5u_softmax_config1g8j)' using Shift Registers.\n",
      "INFO: [RTMG 210-278] Implementing memory 'myproject_axi_tmp_data_V_ram (RAM)' using block RAMs.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'in_local_V_data_0_V_U(fifo_w16_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'in_local_V_data_1_V_U(fifo_w16_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'in_local_V_data_2_V_U(fifo_w16_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'in_local_V_data_3_V_U(fifo_w16_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'in_local_V_data_4_V_U(fifo_w16_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'in_local_V_data_5_V_U(fifo_w16_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'in_local_V_data_6_V_U(fifo_w16_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'in_local_V_data_7_V_U(fifo_w16_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'in_local_V_data_8_V_U(fifo_w16_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'in_local_V_data_9_V_U(fifo_w16_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'in_local_V_data_10_V_U(fifo_w16_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'in_local_V_data_11_V_U(fifo_w16_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'in_local_V_data_12_V_U(fifo_w16_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'in_local_V_data_13_V_U(fifo_w16_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'in_local_V_data_14_V_U(fifo_w16_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'in_local_V_data_15_V_U(fifo_w16_d16_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'out_local_V_data_0_V_U(fifo_w16_d5_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'out_local_V_data_1_V_U(fifo_w16_d5_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'out_local_V_data_2_V_U(fifo_w16_d5_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'out_local_V_data_3_V_U(fifo_w16_d5_A)' using Shift Registers.\n",
      "INFO: [RTMG 210-285] Implementing FIFO 'out_local_V_data_4_V_U(fifo_w16_d5_A)' using Shift Registers.\n",
      "INFO: [HLS 200-111] Finished generating all RTL models Time (s): cpu = 00:08:48 ; elapsed = 00:09:18 . Memory (MB): peak = 1941.301 ; gain = 1240.016 ; free physical = 159 ; free virtual = 12162\n",
      "INFO: [VHDL 208-304] Generating VHDL RTL for myproject_axi.\n",
      "INFO: [VLOG 209-307] Generating Verilog RTL for myproject_axi.\n",
      "***** C/RTL SYNTHESIS COMPLETED IN 0h9m14s *****\n",
      "***** EXPORT IP *****\n",
      "INFO: [IMPL 213-8] Exporting RTL as a Vivado IP.\n",
      "\n",
      "****** Vivado v2019.1 (64-bit)\n",
      "  **** SW Build 2552052 on Fri May 24 14:47:09 MDT 2019\n",
      "  **** IP Build 2548770 on Fri May 24 18:01:18 MDT 2019\n",
      "    ** Copyright 1986-2019 Xilinx, Inc. All Rights Reserved.\n",
      "\n",
      "source run_ippack.tcl -notrace\n",
      "INFO: [IP_Flow 19-234] Refreshing IP repositories\n",
      "INFO: [IP_Flow 19-1704] No user IP repositories specified\n",
      "INFO: [IP_Flow 19-2313] Loaded Vivado IP repository '/home/bcilab/Xilinx/Vivado/2019.1/data/ip'.\n",
      "WARNING: [IP_Flow 19-4832] The IP name 'myproject_axi_ap_fpext_0_no_dsp_32' you have specified is long. The Windows operating system has path length limitations. It is recommended you use shorter names to reduce the likelihood of issues.\n",
      "create_ip: Time (s): cpu = 00:00:03 ; elapsed = 00:00:06 . Memory (MB): peak = 1438.625 ; gain = 63.980 ; free physical = 120 ; free virtual = 11923\n",
      "INFO: [IP_Flow 19-1686] Generating 'Synthesis' target for IP 'myproject_axi_ap_fpext_0_no_dsp_32'...\n",
      "INFO: [IP_Flow 19-1686] Generating 'Simulation' target for IP 'myproject_axi_ap_fpext_0_no_dsp_32'...\n",
      "INFO: [IP_Flow 19-234] Refreshing IP repositories\n",
      "INFO: [IP_Flow 19-1704] No user IP repositories specified\n",
      "INFO: [IP_Flow 19-2313] Loaded Vivado IP repository '/home/bcilab/Xilinx/Vivado/2019.1/data/ip'.\n",
      "INFO: [Common 17-206] Exiting Vivado at Wed Jul 27 13:27:05 2022...\n",
      "***** EXPORT IP COMPLETED IN 0h0m32s *****\n",
      "INFO: [HLS 200-112] Total elapsed time: 590.85 seconds; peak allocated memory: 1.176 GB.\n",
      "INFO: [Common 17-206] Exiting vivado_hls at Wed Jul 27 13:27:06 2022...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'EstimatedClockPeriod': '8.750',\n",
       " 'BestLatency': '123',\n",
       " 'WorstLatency': '123',\n",
       " 'IntervalMin': '124',\n",
       " 'IntervalMax': '124',\n",
       " 'BRAM_18K': '352',\n",
       " 'DSP48E': '515',\n",
       " 'FF': '14051',\n",
       " 'LUT': '120463',\n",
       " 'URAM': '0',\n",
       " 'AvailableBRAM_18K': '432',\n",
       " 'AvailableDSP48E': '360',\n",
       " 'AvailableFF': '141120',\n",
       " 'AvailableLUT': '70560',\n",
       " 'AvailableURAM': '0'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hls_model.build(csim=False, synth=True, export=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9657cded",
   "metadata": {},
   "outputs": [],
   "source": [
    " hls4ml.writer.vivado_accelerator_writer.VivadoAcceleratorWriter.write_header_file(hls_model, X_test, y_test, y_keras, y_hls, 64, 'model/sdk/common/data.h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "320be900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 solution(s) in model//myproject_prj.\n",
      "Reports for solution \"solution1\":\n",
      "\n",
      "C simulation report not found.\n",
      "SYNTHESIS REPORT:\n",
      "================================================================\n",
      "== Vivado HLS Report for 'myproject_axi'\n",
      "================================================================\n",
      "* Date:           Wed Jul 27 13:26:13 2022\n",
      "\n",
      "* Version:        2019.1 (Build 2552052 on Fri May 24 15:28:33 MDT 2019)\n",
      "* Project:        myproject_prj\n",
      "* Solution:       solution1\n",
      "* Product family: zynquplus\n",
      "* Target device:  xczu3eg-sbva484-1-e\n",
      "\n",
      "\n",
      "================================================================\n",
      "== Performance Estimates\n",
      "================================================================\n",
      "+ Timing (ns): \n",
      "    * Summary: \n",
      "    +--------+-------+----------+------------+\n",
      "    |  Clock | Target| Estimated| Uncertainty|\n",
      "    +--------+-------+----------+------------+\n",
      "    |ap_clk  |  10.00|     8.750|        1.25|\n",
      "    +--------+-------+----------+------------+\n",
      "\n",
      "+ Latency (clock cycles): \n",
      "    * Summary: \n",
      "    +-----+-----+-----+-----+---------+\n",
      "    |  Latency  |  Interval | Pipeline|\n",
      "    | min | max | min | max |   Type  |\n",
      "    +-----+-----+-----+-----+---------+\n",
      "    |  123|  123|  123|  123|   none  |\n",
      "    +-----+-----+-----+-----+---------+\n",
      "\n",
      "    + Detail: \n",
      "        * Instance: \n",
      "        +----------------------+-----------+-----+-----+-----+-----+----------+\n",
      "        |                      |           |  Latency  |  Interval | Pipeline |\n",
      "        |       Instance       |   Module  | min | max | min | max |   Type   |\n",
      "        +----------------------+-----------+-----+-----+-----+-----+----------+\n",
      "        |grp_myproject_fu_583  |myproject  |   21|   21|    5|    6| dataflow |\n",
      "        +----------------------+-----------+-----+-----+-----+-----+----------+\n",
      "\n",
      "        * Loop: \n",
      "        +----------+-----+-----+----------+-----------+-----------+------+----------+\n",
      "        |          |  Latency  | Iteration|  Initiation Interval  | Trip |          |\n",
      "        | Loop Name| min | max |  Latency |  achieved |   target  | Count| Pipelined|\n",
      "        +----------+-----+-----+----------+-----------+-----------+------+----------+\n",
      "        |- Loop 1  |   64|   64|         4|          -|          -|    16|    no    |\n",
      "        |- Loop 2  |   20|   20|         4|          -|          -|     5|    no    |\n",
      "        +----------+-----+-----+----------+-----------+-----------+------+----------+\n",
      "\n",
      "\n",
      "\n",
      "================================================================\n",
      "== Utilization Estimates\n",
      "================================================================\n",
      "* Summary: \n",
      "+-----------------+---------+-------+--------+--------+-----+\n",
      "|       Name      | BRAM_18K| DSP48E|   FF   |   LUT  | URAM|\n",
      "+-----------------+---------+-------+--------+--------+-----+\n",
      "|DSP              |        -|      -|       -|       -|    -|\n",
      "|Expression       |        -|      -|      40|    5899|    -|\n",
      "|FIFO             |        0|      -|     137|     652|    -|\n",
      "|Instance         |      351|    515|   13292|  113461|    -|\n",
      "|Memory           |        1|      -|       0|       0|    0|\n",
      "|Multiplexer      |        -|      -|       -|     451|    -|\n",
      "|Register         |        -|      -|     582|       -|    -|\n",
      "+-----------------+---------+-------+--------+--------+-----+\n",
      "|Total            |      352|    515|   14051|  120463|    0|\n",
      "+-----------------+---------+-------+--------+--------+-----+\n",
      "|Available        |      432|    360|  141120|   70560|    0|\n",
      "+-----------------+---------+-------+--------+--------+-----+\n",
      "|Utilization (%)  |       81|    143|       9|     170|    0|\n",
      "+-----------------+---------+-------+--------+--------+-----+\n",
      "\n",
      "+ Detail: \n",
      "    * Instance: \n",
      "    +---------------------------------------+---------------------------------+---------+-------+-------+--------+-----+\n",
      "    |                Instance               |              Module             | BRAM_18K| DSP48E|   FF  |   LUT  | URAM|\n",
      "    +---------------------------------------+---------------------------------+---------+-------+-------+--------+-----+\n",
      "    |grp_myproject_fu_583                   |myproject                        |      347|    515|  12056|  111994|    0|\n",
      "    |myproject_axi_CTRL_BUS_s_axi_U         |myproject_axi_CTRL_BUS_s_axi     |        0|      0|    112|     168|    0|\n",
      "    |myproject_axi_IN_BUS_m_axi_U           |myproject_axi_IN_BUS_m_axi       |        2|      0|    512|     580|    0|\n",
      "    |myproject_axi_OUT_BUS_m_axi_U          |myproject_axi_OUT_BUS_m_axi      |        2|      0|    512|     580|    0|\n",
      "    |myproject_axi_fpext_32ns_64_2_1_U1907  |myproject_axi_fpext_32ns_64_2_1  |        0|      0|    100|     139|    0|\n",
      "    +---------------------------------------+---------------------------------+---------+-------+-------+--------+-----+\n",
      "    |Total                                  |                                 |      351|    515|  13292|  113461|    0|\n",
      "    +---------------------------------------+---------------------------------+---------+-------+-------+--------+-----+\n",
      "\n",
      "Co-simulation report not found.\n"
     ]
    }
   ],
   "source": [
    "hls4ml.report.read_vivado_report('model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18088219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate bitstream and HDF file\n",
    "hls4ml.templates.VivadoAcceleratorBackend.make_bitfile(hls_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
